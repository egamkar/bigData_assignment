Case study for Hadoop Engineers

Hi and welcome to one part of the trivago Hadoop Engineer challenge.
Attached you will find a csv file. Using this file, please work on the following five tasks:

1) Write a Hive query that returns the ten most searched destinations for each 10 minute interval since 00:00:00
2) Write a Hive query that returns the second (distinct) hotel that each user clicked on, and also include all users that did not click on two hotels with a null value.
3) Assuming that the input file above is transferred to the hdfs at /uploads/clicklog_yyyy-mm-dd.csv, create a workflow/job that inserts this data into a hive table at /data/clicklog/, and then inserts the result from task 1 and 2 into separate tables.
4) schedule this workflow/job to execute as soon as the input file is available on hdfs and describe your approach
5) write a UDF for Hive that returns the mdf hash of a given input string.

Please provide us with:
- The Hive queries for tasks 1-3
- The table definititions from task 3
- the workflow/job definition from task 3
- a description of your approach for task 4
- the code of the UDF created in task 5

Please also try to consider performance implications despite the small test data set, and provide your line of thinking.